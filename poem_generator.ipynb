{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WogiPdWehU3O"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YdlaeCBhdfM",
    "outputId": "37c818e5-3106-445e-b128-4e9ee30872a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-03 09:52:51--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.122.128, 172.253.63.128, 142.250.31.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.122.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68970 (67K) [text/plain]\n",
      "Saving to: ‘/tmp/irish-lyrics-eof.txt’\n",
      "\n",
      "\r",
      "          /tmp/iris   0%[                    ]       0  --.-KB/s               \r",
      "/tmp/irish-lyrics-e 100%[===================>]  67.35K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2020-11-03 09:52:51 (124 MB/s) - ‘/tmp/irish-lyrics-eof.txt’ saved [68970/68970]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt \\\n",
    "    -O /tmp/irish-lyrics-eof.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E1zmnyxuhor1"
   },
   "outputs": [],
   "source": [
    "data = open('/tmp/irish-lyrics-eof.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "H4gdI78HhslL",
    "outputId": "23c4a7c3-f936-4309-a0a9-7d192ca1da33"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Come all ye maidens young and fair\\nAnd you that are blooming in your prime\\nAlways beware and keep yo'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vi9-NF6LhtaM"
   },
   "outputs": [],
   "source": [
    "corpus = data.lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1xbu5oIRh5jN",
    "outputId": "ce688b93-2a24-4921-9f98-51153a7b243a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['come all ye maidens young and fair',\n",
       " 'and you that are blooming in your prime',\n",
       " 'always beware and keep your garden fair',\n",
       " 'let no man steal away your thyme',\n",
       " 'for thyme it is a precious thing',\n",
       " 'and thyme brings all things to my mind',\n",
       " 'nlyme with all its flavours, along with all its joys',\n",
       " 'thyme, brings all things to my mind',\n",
       " 'once i and a bunch of thyme',\n",
       " 'i thought it never would decay']"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YjJChLEmh6mz"
   },
   "outputs": [],
   "source": [
    "tok = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UpmTN6HqiCIL"
   },
   "outputs": [],
   "source": [
    "tok.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RP7b563biHFy"
   },
   "outputs": [],
   "source": [
    "total_words = len(tok.word_index) + 1 #1 for out of vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LyRHM7a3iLOt",
    "outputId": "97800f90-3a92-4ad0-9d5e-3dfa49424e76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2690"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FBXlIqu9iQSl"
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tok.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "F_ndnJ70izXm"
   },
   "outputs": [],
   "source": [
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzjWmG9xjXdm",
    "outputId": "1fad3c2e-74a7-46b7-bc0d-9be493b7e5ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 51, 12],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BCKmIxqjAB0",
    "outputId": "300c10c0-c2bc-4841-aa3c-1e11aa863f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 51] \t\t 12\n"
     ]
    }
   ],
   "source": [
    "print(input_sequences[0, :-1],'\\t\\t', input_sequences[0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Z9tuLDmki9Ww"
   },
   "outputs": [],
   "source": [
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ynJ4204jpWn",
    "outputId": "103f4e2f-d473-4e00-a343-807fbc97dcb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0],ys[0, 0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "1vL1fsnIjrlP"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 240, input_length=max_sequence_len-1)) #max_sequence_len-1 because the last sequence code is taken as label i.e. input_sequences[:,-1]\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "adam = Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hBwlSD7kK2F",
    "outputId": "54e59648-7a06-4fec-c4cb-d864c2eb8d90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "377/377 [==============================] - 4s 12ms/step - loss: 6.6386 - accuracy: 0.0763\n",
      "Epoch 2/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 5.8597 - accuracy: 0.1141\n",
      "Epoch 3/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 6.3924 - accuracy: 0.1282\n",
      "Epoch 4/100\n",
      "377/377 [==============================] - 4s 12ms/step - loss: 4.7030 - accuracy: 0.1853\n",
      "Epoch 5/100\n",
      "377/377 [==============================] - 4s 12ms/step - loss: 3.8659 - accuracy: 0.2575\n",
      "Epoch 6/100\n",
      "377/377 [==============================] - 4s 12ms/step - loss: 3.2743 - accuracy: 0.3295\n",
      "Epoch 7/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 2.8342 - accuracy: 0.3917\n",
      "Epoch 8/100\n",
      "377/377 [==============================] - 4s 12ms/step - loss: 2.5457 - accuracy: 0.4366\n",
      "Epoch 9/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 2.2293 - accuracy: 0.4951\n",
      "Epoch 10/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 2.0566 - accuracy: 0.5244\n",
      "Epoch 11/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.9137 - accuracy: 0.5552\n",
      "Epoch 12/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.8488 - accuracy: 0.5692\n",
      "Epoch 13/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.7140 - accuracy: 0.5954\n",
      "Epoch 14/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.6184 - accuracy: 0.6177\n",
      "Epoch 15/100\n",
      "377/377 [==============================] - 4s 12ms/step - loss: 1.5910 - accuracy: 0.6229\n",
      "Epoch 16/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.5287 - accuracy: 0.6355\n",
      "Epoch 17/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.5551 - accuracy: 0.6290\n",
      "Epoch 18/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.4860 - accuracy: 0.6444\n",
      "Epoch 19/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.4358 - accuracy: 0.6563\n",
      "Epoch 20/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.4281 - accuracy: 0.6600\n",
      "Epoch 21/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.4532 - accuracy: 0.6558\n",
      "Epoch 22/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.3721 - accuracy: 0.6704\n",
      "Epoch 23/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.3418 - accuracy: 0.6761\n",
      "Epoch 24/100\n",
      "377/377 [==============================] - 5s 12ms/step - loss: 1.3481 - accuracy: 0.6754\n",
      "Epoch 25/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.3619 - accuracy: 0.6722\n",
      "Epoch 26/100\n",
      "377/377 [==============================] - 5s 12ms/step - loss: 1.3816 - accuracy: 0.6727\n",
      "Epoch 27/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.4268 - accuracy: 0.6602\n",
      "Epoch 28/100\n",
      "377/377 [==============================] - 5s 12ms/step - loss: 1.4584 - accuracy: 0.6550\n",
      "Epoch 29/100\n",
      "377/377 [==============================] - 5s 12ms/step - loss: 1.3602 - accuracy: 0.6737\n",
      "Epoch 30/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.3081 - accuracy: 0.6888\n",
      "Epoch 31/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2740 - accuracy: 0.6965\n",
      "Epoch 32/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2822 - accuracy: 0.6981\n",
      "Epoch 33/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.3262 - accuracy: 0.6892\n",
      "Epoch 34/100\n",
      "377/377 [==============================] - 5s 12ms/step - loss: 1.3175 - accuracy: 0.6936\n",
      "Epoch 35/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2607 - accuracy: 0.7032\n",
      "Epoch 36/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2572 - accuracy: 0.7040\n",
      "Epoch 37/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2668 - accuracy: 0.7037\n",
      "Epoch 38/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2516 - accuracy: 0.7068\n",
      "Epoch 39/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2974 - accuracy: 0.6984\n",
      "Epoch 40/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2982 - accuracy: 0.6992\n",
      "Epoch 41/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.3996 - accuracy: 0.6814\n",
      "Epoch 42/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.3477 - accuracy: 0.6900\n",
      "Epoch 43/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2992 - accuracy: 0.7015\n",
      "Epoch 44/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2520 - accuracy: 0.7094\n",
      "Epoch 45/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2860 - accuracy: 0.7082\n",
      "Epoch 46/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2841 - accuracy: 0.7068\n",
      "Epoch 47/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2786 - accuracy: 0.7068\n",
      "Epoch 48/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2496 - accuracy: 0.7108\n",
      "Epoch 49/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2471 - accuracy: 0.7105\n",
      "Epoch 50/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2822 - accuracy: 0.7034\n",
      "Epoch 51/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2998 - accuracy: 0.7025\n",
      "Epoch 52/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2828 - accuracy: 0.7045\n",
      "Epoch 53/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2373 - accuracy: 0.7173\n",
      "Epoch 54/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2533 - accuracy: 0.7157\n",
      "Epoch 55/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2104 - accuracy: 0.7202\n",
      "Epoch 56/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1891 - accuracy: 0.7295\n",
      "Epoch 57/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1901 - accuracy: 0.7263\n",
      "Epoch 58/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1579 - accuracy: 0.7361\n",
      "Epoch 59/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1718 - accuracy: 0.7294\n",
      "Epoch 60/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2004 - accuracy: 0.7276\n",
      "Epoch 61/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2511 - accuracy: 0.7200\n",
      "Epoch 62/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2702 - accuracy: 0.7164\n",
      "Epoch 63/100\n",
      "377/377 [==============================] - 5s 14ms/step - loss: 1.3434 - accuracy: 0.7022\n",
      "Epoch 64/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.4333 - accuracy: 0.6906\n",
      "Epoch 65/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.3355 - accuracy: 0.6997\n",
      "Epoch 66/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2873 - accuracy: 0.7132\n",
      "Epoch 67/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2227 - accuracy: 0.7235\n",
      "Epoch 68/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1668 - accuracy: 0.7335\n",
      "Epoch 69/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1589 - accuracy: 0.7468\n",
      "Epoch 70/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2302 - accuracy: 0.7303\n",
      "Epoch 71/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.3136 - accuracy: 0.7140\n",
      "Epoch 72/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.4079 - accuracy: 0.6996\n",
      "Epoch 73/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.3561 - accuracy: 0.7100\n",
      "Epoch 74/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2836 - accuracy: 0.7201\n",
      "Epoch 75/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2373 - accuracy: 0.7348\n",
      "Epoch 76/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2128 - accuracy: 0.7404\n",
      "Epoch 77/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2182 - accuracy: 0.7373\n",
      "Epoch 78/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1996 - accuracy: 0.7424\n",
      "Epoch 79/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1588 - accuracy: 0.7421\n",
      "Epoch 80/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2386 - accuracy: 0.7279\n",
      "Epoch 81/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2795 - accuracy: 0.7232\n",
      "Epoch 82/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2478 - accuracy: 0.7304\n",
      "Epoch 83/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2730 - accuracy: 0.7274\n",
      "Epoch 84/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2983 - accuracy: 0.7215\n",
      "Epoch 85/100\n",
      "377/377 [==============================] - 5s 12ms/step - loss: 1.2582 - accuracy: 0.7310\n",
      "Epoch 86/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2758 - accuracy: 0.7252\n",
      "Epoch 87/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2430 - accuracy: 0.7309\n",
      "Epoch 88/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2009 - accuracy: 0.7359\n",
      "Epoch 89/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1508 - accuracy: 0.7504\n",
      "Epoch 90/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1524 - accuracy: 0.7533\n",
      "Epoch 91/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1347 - accuracy: 0.7532\n",
      "Epoch 92/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2065 - accuracy: 0.7455\n",
      "Epoch 93/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2365 - accuracy: 0.7371\n",
      "Epoch 94/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2141 - accuracy: 0.7382\n",
      "Epoch 95/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1870 - accuracy: 0.7449\n",
      "Epoch 96/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1707 - accuracy: 0.7488\n",
      "Epoch 97/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2289 - accuracy: 0.7382\n",
      "Epoch 98/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2368 - accuracy: 0.7401\n",
      "Epoch 99/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.2093 - accuracy: 0.7457\n",
      "Epoch 100/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 1.1839 - accuracy: 0.7495\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f2fcc31ffd0>\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "history = model.fit(xs, ys, epochs=100, verbose=1)\n",
    "#print model.summary()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtAX-1gqkZSH",
    "outputId": "2b8fc5f0-7720-457f-89d7-a0ad68056c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I see a beautiful river here in the land of mooncoin dead and laid out on comes laughing down break far away from spancil hill says along with thee gone years says sure have none deceive me or near but rest with rover from auld rigadoo hearty dying hearty dying dying shannon grow winds love\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"I see a beautiful river\"\n",
    "next_words = 50\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tok.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted = np.argmax(predicted, axis =1)\n",
    "\n",
    "\n",
    "    output_word = \"\"\n",
    "    for word, index in tok.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text = seed_text + \" \" + output_word\n",
    "\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSn7bV_5nUid"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\r\n"
     ]
    }
   ],
   "source": [
    "import jovian\n",
    "jovian.commit(project='nlp-poem-generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "poem-generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
